{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64768bfb-e1de-449b-ba1d-7826b4df9e43",
   "metadata": {},
   "source": [
    "# Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c605903-bc7e-411b-8b54-d7b2db6e94ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from scipy.stats import spearmanr, pearsonr, linregress\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06b29c55-790e-4d07-90eb-b2c286373fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6416aa20-2f61-413c-9db4-1d16887d4279",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30acd1b1-4f25-4f87-abb3-03eb78c57644",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(preds, scores):\n",
    "    pearson_corr, _ = pearsonr(scores, preds)\n",
    "    spearman_corr, _ = spearmanr(scores, preds)\n",
    "    _, _, r, _, _ = linregress(scores, preds) # probably a better way of doing this, fix later\n",
    "    r2 = r**2\n",
    "    mse = ((scores - preds)**2).mean() # Scikit's mean_squared_error complained about being deprecated, so this is my temp fix\n",
    "    return (pearson_corr, spearman_corr, r2, mse)\n",
    "\n",
    "# Make sure these match the metrics above\n",
    "def display_metrics(metrics, title=\"Metrics:\"):\n",
    "    print(title)\n",
    "    print(\"Pearson Corr:\", metrics[0])\n",
    "    print(\"Spearman Corr:\", metrics[1])\n",
    "    print(\"R^2:\", metrics[2])\n",
    "    print(\"MSE:\", metrics[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7ec0c3-c954-46d2-8e92-d0d433819105",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a57ee15f-b442-4e2c-b633-972637861f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = [\"eng\", \"arq\", \"amh\", \"hau\", \"kin\", \"mar\", \"ary\", \"tel\"] # No esp, has no labeled test data\n",
    "#languages = ['eng'] # Use this for much smaller data quantity, but reduce epochs heavily (~200)\n",
    "train_features_list = []\n",
    "train_labels_list = []\n",
    "test_features_list = []\n",
    "test_labels_list = []\n",
    "test_data = {}\n",
    "for lang in languages:\n",
    "    # Load training data\n",
    "    lang_features = torch.load(f\"./processed_data/train_features_{lang}.pt\", weights_only=True)\n",
    "    lang_labels = torch.load(f\"./processed_data/train_labels_{lang}.pt\", weights_only=True)\n",
    "    \n",
    "    # Append to training lists\n",
    "    train_features_list.append(lang_features)\n",
    "    train_labels_list.append(lang_labels)\n",
    "    \n",
    "    # Load test data and store in dictionary\n",
    "    lang_features = torch.load(f\"./processed_data/test_features_{lang}.pt\", weights_only=True)\n",
    "    lang_labels = torch.load(f\"./processed_data/test_labels_{lang}.pt\", weights_only=True)\n",
    "    test_features_list.append(lang_features)\n",
    "    test_labels_list.append(lang_labels)\n",
    "    test_data[lang] = {\"features\": lang_features, \"labels\": lang_labels}\n",
    "    \n",
    "train_features = torch.cat(train_features_list, dim=0)\n",
    "train_labels = torch.cat(train_labels_list, dim=0)\n",
    "test_features = torch.cat(test_features_list, dim=0)\n",
    "test_labels = torch.cat(test_labels_list, dim=0)\n",
    "del train_features_list\n",
    "del train_labels_list\n",
    "del test_features_list\n",
    "del test_labels_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30868a60-d9d5-4150-8f16-c892e7c7fe18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Train Features Shape: torch.Size([13561, 1542])\n",
      "Combined Train Labels Shape: torch.Size([13561])\n",
      "Combined Test Features Shape: torch.Size([5200, 1542])\n",
      "Combined Test Labels Shape: torch.Size([5200])\n",
      "Test Features Shape (English): torch.Size([2600, 1542])\n",
      "Test Labels Shape (English): torch.Size([2600])\n"
     ]
    }
   ],
   "source": [
    "print(\"Combined Train Features Shape:\", train_features.shape)\n",
    "print(\"Combined Train Labels Shape:\", train_labels.shape)\n",
    "print(\"Combined Test Features Shape:\", test_features.shape)\n",
    "print(\"Combined Test Labels Shape:\", test_labels.shape)\n",
    "print(\"Test Features Shape (English):\", test_data[\"eng\"][\"features\"].shape)\n",
    "print(\"Test Labels Shape (English):\", test_data[\"eng\"][\"labels\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea3be44-af02-40ce-b851-d0c9e57fce47",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec58f905-901f-4b63-8372-368520204f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: torch.Size([13561, 1542])\n",
      "y_train: torch.Size([13561])\n",
      "X_test: torch.Size([5200, 1542])\n",
      "y_test: torch.Size([5200])\n"
     ]
    }
   ],
   "source": [
    "# Used different naming scheme when I merged files\n",
    "X_train = train_features\n",
    "y_train = train_labels\n",
    "X_test = test_features\n",
    "y_test = test_labels\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"y_train:\", y_train.shape)\n",
    "print(\"X_test:\", X_test.shape)\n",
    "print(\"y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f78cb471-6300-4c98-9286-22bd022a589b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed assistance with getting a differentiable spearman correlation for loss function\n",
    "# https://forum.numer.ai/t/differentiable-spearman-in-pytorch-optimize-for-corr-directly/2287/26\n",
    "import torchsort\n",
    "\n",
    "def corrcoef(target, pred):\n",
    "    pred_n = pred - pred.mean()\n",
    "    target_n = target - target.mean()\n",
    "    pred_n = pred_n / pred_n.norm()\n",
    "    target_n = target_n / target_n.norm()\n",
    "    return (pred_n * target_n).sum()\n",
    "\n",
    "def spearman_loss(pred, target, x=1e-2):\n",
    "    pred = torchsort.soft_rank(pred.reshape(1,-1),regularization_strength=x)\n",
    "    target = torchsort.soft_rank(target.reshape(1,-1),regularization_strength=x)\n",
    "    pred = pred - pred.mean()\n",
    "    pred = pred / pred.norm()\n",
    "    target = target - target.mean()\n",
    "    target = target / target.norm()\n",
    "    return 1 - (pred * target).sum()**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b2dcb40-a67b-4daa-8784-9309217bceeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size=1539, hidden_size=256, num_layers=2, dropout_rate=0.3):\n",
    "        super(Model, self).__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size, hidden_size, num_layers=num_layers, \n",
    "            batch_first=True, bidirectional=True\n",
    "        )\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(hidden_size * 2, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc = nn.Linear(hidden_size * 2, 1)\n",
    "        self.scale = nn.Parameter(torch.ones(1))\n",
    "        self.shift = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        lstm_out, _ = self.lstm(x) \n",
    "        \n",
    "        # Attention \n",
    "        attention_weights = self.attention(lstm_out)  \n",
    "        weighted_sum = torch.sum(attention_weights * lstm_out, dim=1)  # Get tge attention weight sum\n",
    "        \n",
    "        # Dropout and connected layer\n",
    "        weighted_sum = self.dropout(weighted_sum)\n",
    "        output = self.fc(weighted_sum)  # (batch_size, 1)\n",
    "        \n",
    "        output = output * self.scale + self.shift  # (batch_size, 1)\n",
    "        return output\n",
    "\n",
    "    def split(self, X, y, s=0.8):\n",
    "        dataset = TensorDataset(X.clone().detach(), y.clone().detach())\n",
    "        train_size = int(s * len(dataset))\n",
    "        val_size = len(dataset) - train_size\n",
    "        train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "        \n",
    "        X_train, y_train = zip(*train_dataset)\n",
    "        X_train = torch.stack(X_train)\n",
    "        y_train = torch.stack(y_train)\n",
    "\n",
    "        X_val, y_val = zip(*val_dataset)\n",
    "        X_val = torch.stack(X_val)\n",
    "        y_val = torch.stack(y_val)\n",
    "        \n",
    "        return X_train, y_train, X_val, y_val\n",
    "\n",
    "    def fit(self, X, y, num_epochs=20, lr=1e-4, weight_decay=1e-4):\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        X_train, y_train, X_val, y_val = self.split(X, y)\n",
    "        optimizer = optim.Adam(self.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        best_val_loss = float('inf')\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            self.train()\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = self(X_train)\n",
    "            loss = nn.functional.mse_loss(y_train.squeeze(), y_pred.squeeze())\n",
    "            #loss =spearman_loss(y_train, y_pred)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            self.eval()\n",
    "            with torch.no_grad():\n",
    "                val_pred = self(X_val)\n",
    "                val_loss = nn.functional.mse_loss(y_val.squeeze(), val_pred.squeeze())\n",
    "                #val_loss = spearman_loss(y_val, val_pred).item()\n",
    "\n",
    "            if epoch % (num_epochs // 10) == 0 or epoch == num_epochs - 1:\n",
    "                print(f\"Epoch {epoch+1}/{num_epochs}, Spearman Loss: {loss.item():.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                torch.save(self.state_dict(), './best_model.pth')\n",
    "        print(\"Best val loss:\", best_val_loss)\n",
    "                \n",
    "    def predict(self, x):\n",
    "        x = x.to(device)\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            return self(x).cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a40b67f-2fe6-4a0c-85c1-83184ba73083",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformation(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Transformation, self).__init__()\n",
    "        self.scale = nn.Parameter(torch.ones(1))\n",
    "        self.shift = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.ndim == 1:\n",
    "            x = x.unsqueeze(-1)\n",
    "        return x * self.scale + self.shift\n",
    "    \n",
    "    def fit(self, X_train, y_train, num_epochs=2000, lr=0.1):\n",
    "        optimizer = optim.Adam(self.parameters(), lr)\n",
    "        for epoch in range(num_epochs):\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = self(X_train)\n",
    "            loss = nn.functional.mse_loss(y_train.squeeze(), y_pred.squeeze())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if epoch % (num_epochs // 10) == 0 or epoch == num_epochs - 1:\n",
    "                print(f\"Epoch {epoch+1}/{num_epochs}, MSE Loss: {loss.item():.4f}\")\n",
    "                \n",
    "    def transform(self, x):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            return self(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "90d96dea-ccff-480c-b3f1-cb663fff8ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000, Spearman Loss: 0.2805, Val Loss: 2447.4849\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m y \u001b[38;5;241m=\u001b[39m y_train\n\u001b[0;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m Model(input_size\u001b[38;5;241m=\u001b[39mX_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], hidden_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m, num_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m----> 4\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0001\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m raw_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X)\n\u001b[0;32m      8\u001b[0m trans \u001b[38;5;241m=\u001b[39m Transformation()\n",
      "Cell \u001b[1;32mIn[22], line 78\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, X, y, num_epochs, lr, weight_decay)\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m val_loss \u001b[38;5;241m<\u001b[39m best_val_loss:\n\u001b[0;32m     77\u001b[0m         best_val_loss \u001b[38;5;241m=\u001b[39m val_loss\n\u001b[1;32m---> 78\u001b[0m         \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./best_model.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest val loss:\u001b[39m\u001b[38;5;124m\"\u001b[39m, best_val_loss)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\serialization.py:850\u001b[0m, in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[0;32m    848\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m    849\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m--> 850\u001b[0m         \u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m            \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m            \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_disable_byteorder_record\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    856\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    857\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\serialization.py:1114\u001b[0m, in \u001b[0;36m_save\u001b[1;34m(obj, zip_file, pickle_module, pickle_protocol, _disable_byteorder_record)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     storage \u001b[38;5;241m=\u001b[39m storage\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[0;32m   1113\u001b[0m \u001b[38;5;66;03m# Now that it is on the CPU we can directly copy it into the zip file\u001b[39;00m\n\u001b[1;32m-> 1114\u001b[0m \u001b[43mzip_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X = X_train\n",
    "y = y_train\n",
    "model = Model(input_size=X_train.shape[1], hidden_size=512, num_layers=2).to(device)\n",
    "model.fit(X, y, num_epochs=2000, lr=0.1, weight_decay=0.0001)\n",
    "\n",
    "raw_pred = model.predict(X)\n",
    "\n",
    "trans = Transformation()\n",
    "trans.fit(raw_pred, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a991ee-2fc4-4aef-b539-fbd9ae6c452c",
   "metadata": {},
   "source": [
    "# Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e004cb6c-422e-470e-a2fd-3f414e141ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load('./best_model.pth', map_location=torch.device('cpu'), weights_only=True)\n",
    "model.load_state_dict(state_dict)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a854e3-d29b-4207-99cc-75a53a699dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = model.predict(X_train)\n",
    "test_preds = model.predict(X_test)\n",
    "\n",
    "train_preds_np = np.array(train_preds).flatten()\n",
    "train_y_np = np.array(y_train).flatten()\n",
    "test_preds_np = np.array(test_preds).flatten()\n",
    "test_y_np = np.array(y_test).flatten()\n",
    "\n",
    "train_metrics = calculate_metrics(train_y_np, train_preds_np)\n",
    "test_metrics = calculate_metrics(test_y_np, test_preds_np)\n",
    "full_metrics = calculate_metrics(np.concatenate((train_y_np, test_y_np), axis=0),\n",
    "                                 np.concatenate((train_preds_np, test_preds_np), axis=0))\n",
    "\n",
    "display_metrics(train_metrics, \"Training Metrics:\")\n",
    "print()\n",
    "display_metrics(test_metrics, \"Testing Metrics:\")\n",
    "print()\n",
    "display_metrics(full_metrics, \"Full data Metrics:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0105f3-93d8-47a8-b7ca-a43c067636ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds_trans = trans.transform(train_preds)\n",
    "test_preds_trans = trans.transform(test_preds)\n",
    "\n",
    "train_preds_trans_np = np.array(train_preds_trans).flatten()\n",
    "train_y_trans_np = np.array(y_train).flatten()\n",
    "test_preds_trans_np = np.array(test_preds_trans).flatten()\n",
    "test_y_trans_np = np.array(y_test).flatten()\n",
    "\n",
    "train_dice_preds = X_train[:, -1].numpy().flatten()\n",
    "test_dice_preds = X_test[:, -1].numpy().flatten()\n",
    "\n",
    "train_metrics_trans = calculate_metrics(train_y_trans_np, train_preds_trans_np)\n",
    "test_metrics_trans = calculate_metrics(test_y_trans_np, test_preds_trans_np)\n",
    "full_metrics_trans = calculate_metrics(np.concatenate((train_y_trans_np, test_y_trans_np), axis=0),\n",
    "                                 np.concatenate((train_preds_trans_np, test_preds_trans_np), axis=0))\n",
    "train_dice_metrics_trans = calculate_metrics(train_y_trans_np, train_dice_preds)\n",
    "test_dice_metrics_trans = calculate_metrics(test_y_trans_np, test_dice_preds)\n",
    "full_dice_metrics_trans = calculate_metrics(np.concatenate((train_y_trans_np, test_y_trans_np), axis=0),\n",
    "                                 np.concatenate((train_dice_preds, test_dice_preds), axis=0))\n",
    "\n",
    "display_metrics(train_metrics_trans, \"Training Metrics:\")\n",
    "print()\n",
    "display_metrics(test_metrics_trans, \"Testing Metrics:\")\n",
    "print()\n",
    "display_metrics(full_metrics_trans, \"Full data Metrics:\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b3d650-c682-47b7-ab37-4ef05ac04072",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_metrics(train_dice_metrics_trans, \"Dice Training Metrics:\")\n",
    "print()\n",
    "display_metrics(test_dice_metrics_trans, \"Dice Testing Metrics:\")\n",
    "print()\n",
    "display_metrics(full_dice_metrics_trans, \"Dice Full Metrics:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a28f9e5-d3a2-4d09-a961-0662591dea92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
