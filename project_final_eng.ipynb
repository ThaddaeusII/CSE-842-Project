{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/shmuhammadd/semantic_relatedness/blob/main/Simple_English_Baseline_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ewwVGDM3IyXY"
   },
   "source": [
    "# Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "T6myajMlIyXZ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "from scipy.stats import spearmanr, pearsonr, linregress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "12.4\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())  # Should return True if CUDA is available\n",
    "print(torch.version.cuda)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Irz_4Wm6IyXb"
   },
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(preds, scores):\n",
    "    pearson_corr, _ = pearsonr(scores, preds)\n",
    "    spearman_corr, _ = spearmanr(scores, preds)\n",
    "    _, _, r, _, _ = linregress(scores, preds) # probably a better way of doing this, fix later\n",
    "    r2 = r**2\n",
    "    mse = ((scores - preds)**2).mean() # Scikit's mean_squared_error complained about being deprecated, so this is my temp fix\n",
    "    return (pearson_corr, spearman_corr, r2, mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure these match the metrics above\n",
    "def display_metrics(metrics, title=\"Metrics:\"):\n",
    "    print(title)\n",
    "    print(\"Pearson Corr:\", metrics[0])\n",
    "    print(\"Spearman Corr:\", metrics[1])\n",
    "    print(\"R^2:\", metrics[2])\n",
    "    print(\"MSE:\", metrics[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = [\"eng\", \"arq\", \"amh\", \"hau\", \"kin\", \"mar\", \"ary\", \"tel\"] # No esp, has no labeled test data\n",
    "#languages = ['eng'] # Use this for much smaller data quantity, but reduce epochs heavily (~200)\n",
    "train_features_list = []\n",
    "train_labels_list = []\n",
    "test_features_list = []\n",
    "test_labels_list = []\n",
    "test_data = {}\n",
    "for lang in languages:\n",
    "    # Load training data\n",
    "    lang_features = torch.load(f\"./processed_data/train_features_{lang}.pt\", weights_only=True)\n",
    "    lang_labels = torch.load(f\"./processed_data/train_labels_{lang}.pt\", weights_only=True)\n",
    "    \n",
    "    # Append to training lists\n",
    "    train_features_list.append(lang_features)\n",
    "    train_labels_list.append(lang_labels)\n",
    "    \n",
    "    # Load test data and store in dictionary\n",
    "    lang_features = torch.load(f\"./processed_data/test_features_{lang}.pt\", weights_only=True)\n",
    "    lang_labels = torch.load(f\"./processed_data/test_labels_{lang}.pt\", weights_only=True)\n",
    "    test_features_list.append(lang_features)\n",
    "    test_labels_list.append(lang_labels)\n",
    "    test_data[lang] = {\"features\": lang_features, \"labels\": lang_labels}\n",
    "    \n",
    "train_features = torch.cat(train_features_list, dim=0)\n",
    "train_labels = torch.cat(train_labels_list, dim=0)\n",
    "test_features = torch.cat(test_features_list, dim=0)\n",
    "test_labels = torch.cat(test_labels_list, dim=0)\n",
    "del train_features_list\n",
    "del train_labels_list\n",
    "del test_features_list\n",
    "del test_labels_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Train Features Shape: torch.Size([13561, 1542])\n",
      "Combined Train Labels Shape: torch.Size([13561])\n",
      "Combined Test Features Shape: torch.Size([5200, 1542])\n",
      "Combined Test Labels Shape: torch.Size([5200])\n",
      "Test Features Shape (English): torch.Size([2600, 1542])\n",
      "Test Labels Shape (English): torch.Size([2600])\n"
     ]
    }
   ],
   "source": [
    "print(\"Combined Train Features Shape:\", train_features.shape)\n",
    "print(\"Combined Train Labels Shape:\", train_labels.shape)\n",
    "print(\"Combined Test Features Shape:\", test_features.shape)\n",
    "print(\"Combined Test Labels Shape:\", test_labels.shape)\n",
    "print(\"Test Features Shape (English):\", test_data[\"eng\"][\"features\"].shape)\n",
    "print(\"Test Labels Shape (English):\", test_data[\"eng\"][\"labels\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Make sure you have these files, either run \"project_final_preprocessing.ipynb\" or download the files\\ntrain_features = torch.load(\"train_features_eng.pt\", weights_only=True)\\ntrain_labels = torch.load(\"train_labels_eng.pt\", weights_only=True)\\ntest_features = torch.load(\"test_features_eng.pt\", weights_only=True)\\ntest_labels = torch.load(\"test_labels_end.pt\", weights_only=True)\\n\\nprint(\"Train features:\", train_features.shape)\\nprint(\"Train labels:\", train_labels.shape)\\nprint(\"Test features:\", test_features.shape)\\nprint(\"Test labels:\", test_labels.shape)\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Make sure you have these files, either run \"project_final_preprocessing.ipynb\" or download the files\n",
    "train_features = torch.load(\"train_features_eng.pt\", weights_only=True)\n",
    "train_labels = torch.load(\"train_labels_eng.pt\", weights_only=True)\n",
    "test_features = torch.load(\"test_features_eng.pt\", weights_only=True)\n",
    "test_labels = torch.load(\"test_labels_end.pt\", weights_only=True)\n",
    "\n",
    "print(\"Train features:\", train_features.shape)\n",
    "print(\"Train labels:\", train_labels.shape)\n",
    "print(\"Test features:\", test_features.shape)\n",
    "print(\"Test labels:\", test_labels.shape)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: torch.Size([13561, 1542])\n",
      "y_train: torch.Size([13561])\n",
      "X_test: torch.Size([5200, 1542])\n",
      "y_test: torch.Size([5200])\n"
     ]
    }
   ],
   "source": [
    "# Used different naming scheme when I merged files\n",
    "X_train = train_features\n",
    "y_train = train_labels\n",
    "X_test = test_features\n",
    "y_test = test_labels\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"y_train:\", y_train.shape)\n",
    "print(\"X_test:\", X_test.shape)\n",
    "print(\"y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed assistance with getting a differentiable spearman correlation for loss function\n",
    "# https://forum.numer.ai/t/differentiable-spearman-in-pytorch-optimize-for-corr-directly/2287/26\n",
    "import torchsort\n",
    "\n",
    "def corrcoef(target, pred):\n",
    "    pred_n = pred - pred.mean()\n",
    "    target_n = target - target.mean()\n",
    "    pred_n = pred_n / pred_n.norm()\n",
    "    target_n = target_n / target_n.norm()\n",
    "    return (pred_n * target_n).sum()\n",
    "\n",
    "def spearman_loss(pred, target, x=1e-2):\n",
    "    pred = torchsort.soft_rank(pred.reshape(1,-1),regularization_strength=x)\n",
    "    target = torchsort.soft_rank(target.reshape(1,-1),regularization_strength=x)\n",
    "    pred = pred - pred.mean()\n",
    "    pred = pred / pred.norm()\n",
    "    target = target - target.mean()\n",
    "    target = target / target.norm()\n",
    "    return 1 - (pred * target).sum()**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size=1539, hidden_size=128, num_layers=1):\n",
    "        super(Model, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers=num_layers, \n",
    "                            batch_first=True, bidirectional=True)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.fc = nn.Linear(hidden_size * 2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        output, _ = self.lstm(x)\n",
    "        output = self.dropout(output)\n",
    "        output = self.fc(output[:, -1, :])\n",
    "        return output\n",
    "    \n",
    "    def split(self, X, y, s = 0.8):\n",
    "        dataset = TensorDataset(X.clone().detach(), y.clone().detach())\n",
    "        train_size = int(s * len(dataset))\n",
    "        val_size = len(dataset) - train_size\n",
    "        train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "        \n",
    "        X_train, y_train = zip(*train_dataset)\n",
    "        X_train = torch.stack(X_train)\n",
    "        y_train = torch.stack(y_train)\n",
    "\n",
    "        X_val, y_val = zip(*val_dataset)\n",
    "        X_val = torch.stack(X_val)\n",
    "        y_val = torch.stack(y_val)\n",
    "        \n",
    "        return X_train, y_train, X_val, y_val\n",
    "    \n",
    "    def fit(self, X, y, num_epochs=20, lr=1e-4, weight_decay=1e-4):\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        X_train, y_train, X_val, y_val = self.split(X, y)\n",
    "        optimizer = optim.Adam(self.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        best_val_loss = float('inf')\n",
    "        for epoch in range(num_epochs):\n",
    "            self.train()\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = self(X_train)\n",
    "            loss = spearman_loss(y_train, y_pred)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            self.eval()\n",
    "            with torch.no_grad():\n",
    "                val_pred = self(X_val)\n",
    "                val_loss = spearman_loss(y_val, val_pred).item()\n",
    "\n",
    "            if epoch % (num_epochs // 10) == 0 or epoch == num_epochs - 1:\n",
    "                print(f\"Epoch {epoch+1}/{num_epochs}, Spearman Loss: {loss.item():.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                torch.save(self.state_dict(), './best_model.pth')\n",
    "        print(\"Best val loss:\", best_val_loss)\n",
    "                \n",
    "    def predict(self, x):\n",
    "        x = x.to(device)\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            return self(x).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformation(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Transformation, self).__init__()\n",
    "        self.scale = nn.Parameter(torch.ones(1))\n",
    "        self.shift = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.ndim == 1:\n",
    "            x = x.unsqueeze(-1)\n",
    "        return x * self.scale + self.shift\n",
    "    \n",
    "    def fit(self, X_train, y_train, num_epochs=1000, lr=0.1):\n",
    "        optimizer = optim.Adam(self.parameters(), lr)\n",
    "        for epoch in range(num_epochs):\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = self(X_train)\n",
    "            loss = nn.functional.mse_loss(y_train.squeeze(), y_pred.squeeze())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if epoch % (num_epochs // 10) == 0 or epoch == num_epochs - 1:\n",
    "                print(f\"Epoch {epoch+1}/{num_epochs}, MSE Loss: {loss.item():.4f}\")\n",
    "                \n",
    "    def transform(self, x):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            return self(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000, Spearman Loss: 0.9985, Val Loss: 0.9900\n",
      "Epoch 201/2000, Spearman Loss: 0.8458, Val Loss: 0.7168\n",
      "Epoch 401/2000, Spearman Loss: 0.7048, Val Loss: 0.6917\n",
      "Epoch 601/2000, Spearman Loss: 0.8986, Val Loss: 0.7165\n",
      "Epoch 801/2000, Spearman Loss: 0.7288, Val Loss: 0.7071\n",
      "Epoch 1001/2000, Spearman Loss: 0.8906, Val Loss: 0.7251\n",
      "Epoch 1201/2000, Spearman Loss: 0.7429, Val Loss: 0.7165\n",
      "Epoch 1401/2000, Spearman Loss: 0.7704, Val Loss: 0.7228\n",
      "Epoch 1601/2000, Spearman Loss: 0.7232, Val Loss: 0.7069\n",
      "Epoch 1801/2000, Spearman Loss: 0.7584, Val Loss: 0.7126\n",
      "Epoch 2000/2000, Spearman Loss: 0.7677, Val Loss: 0.7130\n",
      "Best val loss: 0.6578329801559448\n",
      "Epoch 1/1000, MSE Loss: 902.0722\n",
      "Epoch 101/1000, MSE Loss: 0.0496\n",
      "Epoch 201/1000, MSE Loss: 0.0358\n",
      "Epoch 301/1000, MSE Loss: 0.0346\n",
      "Epoch 401/1000, MSE Loss: 0.0340\n",
      "Epoch 501/1000, MSE Loss: 0.0338\n",
      "Epoch 601/1000, MSE Loss: 0.0337\n",
      "Epoch 701/1000, MSE Loss: 0.0336\n",
      "Epoch 801/1000, MSE Loss: 0.0336\n",
      "Epoch 901/1000, MSE Loss: 0.0336\n",
      "Epoch 1000/1000, MSE Loss: 0.0336\n"
     ]
    }
   ],
   "source": [
    "X = X_train\n",
    "y = y_train\n",
    "model = Model(input_size=X_train.shape[1], hidden_size=512, num_layers=2).to(device)\n",
    "model.fit(X, y, num_epochs=2000, lr=0.1, weight_decay=0.0001)\n",
    "\n",
    "raw_pred = model.predict(X)\n",
    "\n",
    "trans = Transformation()\n",
    "trans.fit(raw_pred, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (lstm): LSTM(1542, 512, num_layers=2, batch_first=True, bidirectional=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (fc): Linear(in_features=1024, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = torch.load('./best_model.pth', map_location=torch.device('cpu'), weights_only=True)\n",
    "model.load_state_dict(state_dict)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Metrics:\n",
      "Pearson Corr: 0.5878588589559477\n",
      "Spearman Corr: 0.5868116648719927\n",
      "R^2: 0.34557802193017434\n",
      "MSE: 312.34805\n",
      "\n",
      "Testing Metrics:\n",
      "Pearson Corr: 0.6134780924511531\n",
      "Spearman Corr: 0.6323575545170608\n",
      "R^2: 0.3763554193159644\n",
      "MSE: 356.2072\n",
      "\n",
      "Full data Metrics:\n",
      "Pearson Corr: 0.5930471918841913\n",
      "Spearman Corr: 0.5972918014663274\n",
      "R^2: 0.3517049306460061\n",
      "MSE: 324.50452\n"
     ]
    }
   ],
   "source": [
    "train_preds = model.predict(X_train)\n",
    "test_preds = model.predict(X_test)\n",
    "\n",
    "train_preds_np = np.array(train_preds).flatten()\n",
    "train_y_np = np.array(y_train).flatten()\n",
    "test_preds_np = np.array(test_preds).flatten()\n",
    "test_y_np = np.array(y_test).flatten()\n",
    "\n",
    "train_metrics = calculate_metrics(train_y_np, train_preds_np)\n",
    "test_metrics = calculate_metrics(test_y_np, test_preds_np)\n",
    "full_metrics = calculate_metrics(np.concatenate((train_y_np, test_y_np), axis=0),\n",
    "                                 np.concatenate((train_preds_np, test_preds_np), axis=0))\n",
    "\n",
    "display_metrics(train_metrics, \"Training Metrics:\")\n",
    "print()\n",
    "display_metrics(test_metrics, \"Testing Metrics:\")\n",
    "print()\n",
    "display_metrics(full_metrics, \"Full data Metrics:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Metrics:\n",
      "Pearson Corr: 0.5878588323754048\n",
      "Spearman Corr: 0.5868116616471577\n",
      "R^2: 0.3455780222473866\n",
      "MSE: 0.10745072\n",
      "\n",
      "Testing Metrics:\n",
      "Pearson Corr: 0.6134780988809436\n",
      "Spearman Corr: 0.6323575417398761\n",
      "R^2: 0.37635542077323936\n",
      "MSE: 0.09497109\n",
      "\n",
      "Full data Metrics:\n",
      "Pearson Corr: 0.5930471873687991\n",
      "Spearman Corr: 0.5972917978263474\n",
      "R^2: 0.35170493123780394\n",
      "MSE: 0.10399174\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_preds_trans = trans.transform(train_preds)\n",
    "test_preds_trans = trans.transform(test_preds)\n",
    "\n",
    "train_preds_trans_np = np.array(train_preds_trans).flatten()\n",
    "train_y_trans_np = np.array(y_train).flatten()\n",
    "test_preds_trans_np = np.array(test_preds_trans).flatten()\n",
    "test_y_trans_np = np.array(y_test).flatten()\n",
    "\n",
    "train_dice_preds = X_train[:, -1].numpy().flatten()\n",
    "test_dice_preds = X_test[:, -1].numpy().flatten()\n",
    "\n",
    "train_metrics_trans = calculate_metrics(train_y_trans_np, train_preds_trans_np)\n",
    "test_metrics_trans = calculate_metrics(test_y_trans_np, test_preds_trans_np)\n",
    "full_metrics_trans = calculate_metrics(np.concatenate((train_y_trans_np, test_y_trans_np), axis=0),\n",
    "                                 np.concatenate((train_preds_trans_np, test_preds_trans_np), axis=0))\n",
    "train_dice_metrics_trans = calculate_metrics(train_y_trans_np, train_dice_preds)\n",
    "test_dice_metrics_trans = calculate_metrics(test_y_trans_np, test_dice_preds)\n",
    "full_dice_metrics_trans = calculate_metrics(np.concatenate((train_y_trans_np, test_y_trans_np), axis=0),\n",
    "                                 np.concatenate((train_dice_preds, test_dice_preds), axis=0))\n",
    "\n",
    "display_metrics(train_metrics_trans, \"Training Metrics:\")\n",
    "print()\n",
    "display_metrics(test_metrics_trans, \"Testing Metrics:\")\n",
    "print()\n",
    "display_metrics(full_metrics_trans, \"Full data Metrics:\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dice Training Metrics:\n",
      "Pearson Corr: 0.5373415969579298\n",
      "Spearman Corr: 0.5224577785209864\n",
      "R^2: 0.28873598082359553\n",
      "MSE: 1.0594916\n",
      "\n",
      "Dice Testing Metrics:\n",
      "Pearson Corr: 0.6112762933539937\n",
      "Spearman Corr: 0.6197246704911602\n",
      "R^2: 0.37365871602039336\n",
      "MSE: 1.0556076\n",
      "\n",
      "Dice Full Metrics:\n",
      "Pearson Corr: 0.5559559434649143\n",
      "Spearman Corr: 0.5476671568020123\n",
      "R^2: 0.3090870272524448\n",
      "MSE: 1.058415\n"
     ]
    }
   ],
   "source": [
    "display_metrics(train_dice_metrics_trans, \"Dice Training Metrics:\")\n",
    "print()\n",
    "display_metrics(test_dice_metrics_trans, \"Dice Testing Metrics:\")\n",
    "print()\n",
    "display_metrics(full_dice_metrics_trans, \"Dice Full Metrics:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train_preds_trans, \"train_preds_all.pt\")\n",
    "torch.save(test_preds_trans, \"test_preds_all.pt\")\n",
    "torch.save(test_dice_preds, \"dice_preds_all.pt\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
