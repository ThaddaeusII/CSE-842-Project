{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/shmuhammadd/semantic_relatedness/blob/main/Simple_English_Baseline_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ewwVGDM3IyXY"
   },
   "source": [
    "# Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "T6myajMlIyXZ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "from scipy.stats import spearmanr, pearsonr, linregress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "12.4\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())  # Should return True if CUDA is available\n",
    "print(torch.version.cuda)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Irz_4Wm6IyXb"
   },
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(preds, scores):\n",
    "    pearson_corr, _ = pearsonr(scores, preds)\n",
    "    spearman_corr, _ = spearmanr(scores, preds)\n",
    "    _, _, r, _, _ = linregress(scores, preds) # probably a better way of doing this, fix later\n",
    "    r2 = r**2\n",
    "    mse = ((scores - preds)**2).mean() # Scikit's mean_squared_error complained about being deprecated, so this is my temp fix\n",
    "    return (pearson_corr, spearman_corr, r2, mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure these match the metrics above\n",
    "def display_metrics(metrics, title=\"Metrics:\"):\n",
    "    print(title)\n",
    "    print(\"Pearson Corr:\", metrics[0])\n",
    "    print(\"Spearman Corr:\", metrics[1])\n",
    "    print(\"R^2:\", metrics[2])\n",
    "    print(\"MSE:\", metrics[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features: torch.Size([5500, 1542])\n",
      "Train labels: torch.Size([5500])\n",
      "Test features: torch.Size([2600, 1542])\n",
      "Test labels: torch.Size([2600])\n"
     ]
    }
   ],
   "source": [
    "# Make sure you have these files, either run \"project_final_preprocessing.ipynb\" or download the files\n",
    "train_features = torch.load(\"train_features.pt\", weights_only=True)\n",
    "train_labels = torch.load(\"train_labels.pt\", weights_only=True)\n",
    "test_features = torch.load(\"test_features.pt\", weights_only=True)\n",
    "test_labels = torch.load(\"test_labels.pt\", weights_only=True)\n",
    "\n",
    "print(\"Train features:\", train_features.shape)\n",
    "print(\"Train labels:\", train_labels.shape)\n",
    "print(\"Test features:\", test_features.shape)\n",
    "print(\"Test labels:\", test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: torch.Size([5500, 1542])\n",
      "y_train: torch.Size([5500])\n",
      "X_test: torch.Size([2600, 1542])\n",
      "y_test: torch.Size([2600])\n"
     ]
    }
   ],
   "source": [
    "# Used different naming scheme when I merged files\n",
    "X_train = train_features\n",
    "y_train = train_labels\n",
    "X_test = test_features\n",
    "y_test = test_labels\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"y_train:\", y_train.shape)\n",
    "print(\"X_test:\", X_test.shape)\n",
    "print(\"y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed assistance with getting a differentiable spearman correlation for loss function\n",
    "# https://forum.numer.ai/t/differentiable-spearman-in-pytorch-optimize-for-corr-directly/2287/26\n",
    "import torchsort\n",
    "\n",
    "def corrcoef(target, pred):\n",
    "    pred_n = pred - pred.mean()\n",
    "    target_n = target - target.mean()\n",
    "    pred_n = pred_n / pred_n.norm()\n",
    "    target_n = target_n / target_n.norm()\n",
    "    return (pred_n * target_n).sum()\n",
    "\n",
    "def spearman_loss(pred, target, x=1e-2):\n",
    "    pred = torchsort.soft_rank(pred.reshape(1,-1),regularization_strength=x)\n",
    "    target = torchsort.soft_rank(target.reshape(1,-1),regularization_strength=x)\n",
    "    pred = pred - pred.mean()\n",
    "    pred = pred / pred.norm()\n",
    "    target = target - target.mean()\n",
    "    target = target / target.norm()\n",
    "    return 1 - (pred * target).sum()**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size=1539, hidden_size=128, num_layers=1):\n",
    "        super(Model, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers=num_layers, \n",
    "                            batch_first=True, bidirectional=True)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.fc = nn.Linear(hidden_size * 2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        output, _ = self.lstm(x)\n",
    "        output = self.dropout(output)\n",
    "        output = self.fc(output[:, -1, :])\n",
    "        return output\n",
    "    \n",
    "    def split(self, X, y, s = 0.8):\n",
    "        dataset = TensorDataset(X.clone().detach(), y.clone().detach())\n",
    "        train_size = int(s * len(dataset))\n",
    "        val_size = len(dataset) - train_size\n",
    "        train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "        \n",
    "        X_train, y_train = zip(*train_dataset)\n",
    "        X_train = torch.stack(X_train)\n",
    "        y_train = torch.stack(y_train)\n",
    "\n",
    "        X_val, y_val = zip(*val_dataset)\n",
    "        X_val = torch.stack(X_val)\n",
    "        y_val = torch.stack(y_val)\n",
    "        \n",
    "        return X_train, y_train, X_val, y_val\n",
    "    \n",
    "    def fit(self, X, y, num_epochs=20, lr=1e-4, weight_decay=1e-4):\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        X_train, y_train, X_val, y_val = self.split(X, y)\n",
    "        optimizer = optim.Adam(self.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        best_val_loss = float('inf')\n",
    "        for epoch in range(num_epochs):\n",
    "            self.train()\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = self(X_train)\n",
    "            loss = spearman_loss(y_train, y_pred)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            self.eval()\n",
    "            with torch.no_grad():\n",
    "                val_pred = self(X_val)\n",
    "                val_loss = spearman_loss(y_val, val_pred).item()\n",
    "\n",
    "            if epoch % (num_epochs // 10) == 0 or epoch == num_epochs - 1:\n",
    "                print(f\"Epoch {epoch+1}/{num_epochs}, Spearman Loss: {loss.item():.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                torch.save(self.state_dict(), './best_model.pth')\n",
    "                \n",
    "    def predict(self, x):\n",
    "        x = x.to(device)\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            return self(x).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformation(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Transformation, self).__init__()\n",
    "        self.scale = nn.Parameter(torch.ones(1))\n",
    "        self.shift = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.ndim == 1:\n",
    "            x = x.unsqueeze(-1)\n",
    "        return x * self.scale + self.shift\n",
    "    \n",
    "    def fit(self, X_train, y_train, num_epochs=1000, lr=0.1):\n",
    "        optimizer = optim.Adam(self.parameters(), lr)\n",
    "        for epoch in range(num_epochs):\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = self(X_train)\n",
    "            loss = nn.functional.mse_loss(y_train.squeeze(), y_pred.squeeze())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if epoch % (num_epochs // 10) == 0 or epoch == num_epochs - 1:\n",
    "                print(f\"Epoch {epoch+1}/{num_epochs}, MSE Loss: {loss.item():.4f}\")\n",
    "                \n",
    "    def transform(self, x):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            return self(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Spearman Loss: 0.9989, Val Loss: 0.8948\n",
      "Epoch 3/20, Spearman Loss: 0.9815, Val Loss: 0.9283\n",
      "Epoch 5/20, Spearman Loss: 0.9796, Val Loss: 0.6928\n",
      "Epoch 7/20, Spearman Loss: 0.8823, Val Loss: 0.7179\n",
      "Epoch 9/20, Spearman Loss: 0.7391, Val Loss: 0.6945\n",
      "Epoch 11/20, Spearman Loss: 0.7175, Val Loss: 0.6825\n",
      "Epoch 13/20, Spearman Loss: 0.7102, Val Loss: 0.6698\n",
      "Epoch 15/20, Spearman Loss: 0.6854, Val Loss: 0.6616\n",
      "Epoch 17/20, Spearman Loss: 0.6882, Val Loss: 0.6570\n",
      "Epoch 19/20, Spearman Loss: 0.7225, Val Loss: 0.6658\n",
      "Epoch 20/20, Spearman Loss: 0.6878, Val Loss: 0.6605\n",
      "Epoch 1/1000, MSE Loss: 579.2866\n",
      "Epoch 101/1000, MSE Loss: 27.3292\n",
      "Epoch 201/1000, MSE Loss: 0.2578\n",
      "Epoch 301/1000, MSE Loss: 0.1429\n",
      "Epoch 401/1000, MSE Loss: 0.1352\n",
      "Epoch 501/1000, MSE Loss: 0.1269\n",
      "Epoch 601/1000, MSE Loss: 0.1183\n",
      "Epoch 701/1000, MSE Loss: 0.1096\n",
      "Epoch 801/1000, MSE Loss: 0.1010\n",
      "Epoch 901/1000, MSE Loss: 0.0926\n",
      "Epoch 1000/1000, MSE Loss: 0.0848\n"
     ]
    }
   ],
   "source": [
    "X = X_train\n",
    "y = y_train\n",
    "model = Model(input_size=X_train.shape[1], hidden_size=512, num_layers=2).to(device)\n",
    "model.fit(X, y, num_epochs=200, lr=0.1, weight_decay=0.0001)\n",
    "\n",
    "raw_pred = model.predict(X)\n",
    "\n",
    "trans = Transformation()\n",
    "trans.fit(raw_pred, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Metrics:\n",
      "Pearson Corr: -0.6029928549730796\n",
      "Spearman Corr: -0.5835302496054595\n",
      "R^2: 0.36360035827483894\n",
      "MSE: 579.28656\n",
      "\n",
      "Testing Metrics:\n",
      "Pearson Corr: -0.7206108533119391\n",
      "Spearman Corr: -0.7079363766386325\n",
      "R^2: 0.5192799820257603\n",
      "MSE: 620.46063\n",
      "\n",
      "Full data Metrics:\n",
      "Pearson Corr: -0.6287314715345089\n",
      "Spearman Corr: -0.6185839880233847\n",
      "R^2: 0.3953033387742675\n",
      "MSE: 592.5029\n"
     ]
    }
   ],
   "source": [
    "train_preds = model.predict(X_train)\n",
    "test_preds = model.predict(X_test)\n",
    "\n",
    "train_preds_np = np.array(train_preds).flatten()\n",
    "train_y_np = np.array(y_train).flatten()\n",
    "test_preds_np = np.array(test_preds).flatten()\n",
    "test_y_np = np.array(y_test).flatten()\n",
    "\n",
    "train_metrics = calculate_metrics(train_y_np, train_preds_np)\n",
    "test_metrics = calculate_metrics(test_y_np, test_preds_np)\n",
    "full_metrics = calculate_metrics(np.concatenate((train_y_np, test_y_np), axis=0),\n",
    "                                 np.concatenate((train_preds_np, test_preds_np), axis=0))\n",
    "\n",
    "display_metrics(train_metrics, \"Training Metrics:\")\n",
    "print()\n",
    "display_metrics(test_metrics, \"Testing Metrics:\")\n",
    "print()\n",
    "display_metrics(full_metrics, \"Full data Metrics:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred vs True for training data\n",
      "-43.9898, 1.0000\n",
      "-44.1358, 1.0000\n",
      "-26.5160, 1.0000\n",
      "-43.2582, 1.0000\n",
      "-42.0905, 1.0000\n",
      "-43.7051, 1.0000\n",
      "-43.4124, 1.0000\n",
      "-43.6525, 1.0000\n",
      "-43.5668, 1.0000\n",
      "-43.7499, 1.0000\n",
      "\n",
      "Pred vs True for testing data\n",
      "-19.3353, 0.7000\n",
      "-14.9599, 0.7100\n",
      "-11.5634, 0.4900\n",
      "-12.8064, 0.2700\n",
      "-5.4662, 0.3200\n",
      "-17.5851, 0.4300\n",
      "-10.1705, 0.3100\n",
      "-7.9478, 0.3200\n",
      "-26.5567, 0.7700\n",
      "-13.3385, 0.3400\n"
     ]
    }
   ],
   "source": [
    "print(\"Pred vs True for training data\")\n",
    "for i in range(10):\n",
    "    print(f\"{train_preds_np[i]:.4f}, {train_labels[i]:.4f}\")\n",
    "print()\n",
    "print(\"Pred vs True for testing data\")\n",
    "for i in range(10):\n",
    "    print(f\"{test_preds_np[i]:.4f}, {test_labels[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Metrics:\n",
      "Pearson Corr: -0.6029928035196528\n",
      "Spearman Corr: -0.583530192301254\n",
      "R^2: 0.36360035907285937\n",
      "MSE: 0.084676795\n",
      "\n",
      "Testing Metrics:\n",
      "Pearson Corr: -0.7206109057057404\n",
      "Spearman Corr: -0.7079363062400054\n",
      "R^2: 0.5192799796160503\n",
      "MSE: 0.06157634\n"
     ]
    }
   ],
   "source": [
    "train_preds_trans = trans.transform(train_preds)\n",
    "test_preds_trans = trans.transform(test_preds)\n",
    "\n",
    "train_preds_trans_np = np.array(train_preds_trans).flatten()\n",
    "train_y_trans_np = np.array(y_train).flatten()\n",
    "test_preds_trans_np = np.array(test_preds_trans).flatten()\n",
    "test_y_trans_np = np.array(y_test).flatten()\n",
    "\n",
    "train_metrics_trans = calculate_metrics(train_y_trans_np, train_preds_trans_np)\n",
    "test_metrics_trans = calculate_metrics(test_y_trans_np, test_preds_trans_np)\n",
    "\n",
    "display_metrics(train_metrics_trans, \"Training Metrics:\")\n",
    "print()\n",
    "display_metrics(test_metrics_trans, \"Testing Metrics:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred vs True for training data\n",
      "0.4631, 1.0000\n",
      "0.4622, 1.0000\n",
      "0.5716, 1.0000\n",
      "0.4677, 1.0000\n",
      "0.4749, 1.0000\n",
      "0.4649, 1.0000\n",
      "0.4667, 1.0000\n",
      "0.4652, 1.0000\n",
      "0.4658, 1.0000\n",
      "0.4646, 1.0000\n",
      "\n",
      "Pred vs True for testing data\n",
      "0.6162, 0.7000\n",
      "0.6433, 0.7100\n",
      "0.6644, 0.4900\n",
      "0.6567, 0.2700\n",
      "0.7023, 0.3200\n",
      "0.6270, 0.4300\n",
      "0.6731, 0.3100\n",
      "0.6869, 0.3200\n",
      "0.5714, 0.7700\n",
      "0.6534, 0.3400\n"
     ]
    }
   ],
   "source": [
    "print(\"Pred vs True for training data\")\n",
    "for i in range(10):\n",
    "    print(f\"{train_preds_trans_np[i]:.4f}, {train_labels[i]:.4f}\")\n",
    "print()\n",
    "print(\"Pred vs True for testing data\")\n",
    "for i in range(10):\n",
    "    print(f\"{test_preds_trans_np[i]:.4f}, {test_labels[i]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
