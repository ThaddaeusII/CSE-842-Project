{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shmuhammadd/semantic_relatedness/blob/main/Simple_English_Baseline_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewwVGDM3IyXY"
      },
      "source": [
        "# Package Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "T6myajMlIyXZ"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from scipy.stats import spearmanr, pearsonr, linregress\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import Levenshtein\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gn_ikaypIyXZ"
      },
      "source": [
        "# Data Import / Format / Export\n",
        "\n",
        "Functions for importing, formatting, and exporting data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "1PhipxbhIyXa",
        "outputId": "1da7308c-a799-4fe0-897e-3e4a23ea15c2"
      },
      "outputs": [],
      "source": [
        "# Load data from csv, format into proper split\n",
        "def load_data(filepath):\n",
        "    data = pd.read_csv(filepath)\n",
        "    data['Split_Text'] = data['Text'].apply(lambda x: x.split(\"\\n\"))\n",
        "    data['Pred_Score'] = 0.0\n",
        "    return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_data(data, vectorizer=None, fit_vectorizer=True):\n",
        "    # Split sentences into two columns\n",
        "    data[['Sentence1', 'Sentence2']] = pd.DataFrame(data['Split_Text'].tolist(), index=data.index)\n",
        "    \n",
        "    # Lowercasing and removing punctuation\n",
        "    data['Sentence1'] = data['Sentence1'].str.lower().str.translate(str.maketrans('', '', string.punctuation)).str.strip()\n",
        "    data['Sentence2'] = data['Sentence2'].str.lower().str.translate(str.maketrans('', '', string.punctuation)).str.strip()\n",
        "\n",
        "    # Tokenization\n",
        "    data['Tokens_Sentence1'] = data['Sentence1'].apply(lambda x: x.split())\n",
        "    data['Tokens_Sentence2'] = data['Sentence2'].apply(lambda x: x.split())\n",
        "    \n",
        "    # Use TF-IDF vectorization if not passed one\n",
        "    if vectorizer is None:\n",
        "        vectorizer = TfidfVectorizer()\n",
        "        \n",
        "    # Fit the vectorizer if fit_vectorizer=True (training data), else transform (testing data)\n",
        "    tfidf_sentence1 = None\n",
        "    tfidf_sentence2 = None\n",
        "    if fit_vectorizer:\n",
        "        tfidf_sentence1 = vectorizer.fit_transform(data['Sentence1'])\n",
        "        tfidf_sentence2 = vectorizer.transform(data['Sentence2'])\n",
        "    else:\n",
        "        tfidf_sentence1 = vectorizer.transform(data['Sentence1'])\n",
        "        tfidf_sentence2 = vectorizer.transform(data['Sentence2'])\n",
        "    \n",
        "    # --- Cosine Similarity Feature ---\n",
        "    data['Cosine_Similarity'] = [cosine_similarity(tfidf_sentence1[i], tfidf_sentence2[i])[0][0] for i in range(tfidf_sentence1.shape[0])]\n",
        "    \n",
        "    # --- Jaccard Similarity Feature ---\n",
        "    def jaccard_similarity(s1, s2):\n",
        "        set1, set2 = set(s1.split()), set(s2.split())\n",
        "        return len(set1.intersection(set2)) / len(set1.union(set2))\n",
        "    \n",
        "    data['Jaccard_Similarity'] = data.apply(lambda x: jaccard_similarity(x['Sentence1'], x['Sentence2']), axis=1)\n",
        "    \n",
        "    # --- Levenshtein Distance Feature ---\n",
        "    data['Levenshtein_Distance'] = data.apply(lambda x: Levenshtein.distance(x['Sentence1'], x['Sentence2']), axis=1)\n",
        "    \n",
        "    # --- Sentence Length Difference Feature ---\n",
        "    data['Length_Diff'] = data.apply(lambda x: abs(len(x['Sentence1']) - len(x['Sentence2'])), axis=1)\n",
        "    \n",
        "    # --- Word Overlap Feature ---\n",
        "    def word_overlap(s1, s2):\n",
        "        set1, set2 = set(s1.split()), set(s2.split())\n",
        "        return len(set1.intersection(set2)) / len(set1)\n",
        "    \n",
        "    data['Word_Overlap'] = data.apply(lambda x: word_overlap(x['Sentence1'], x['Sentence2']), axis=1)\n",
        "    \n",
        "    # Convert TF-IDF sparse matrices to arrays for combining\n",
        "    tfidf_sentence1_array = tfidf_sentence1.toarray()\n",
        "    tfidf_sentence2_array = tfidf_sentence2.toarray()\n",
        "    \n",
        "    # Create a final array combining features\n",
        "    additional_features = data[['Cosine_Similarity', 'Jaccard_Similarity', 'Levenshtein_Distance', 'Length_Diff', 'Word_Overlap']].values\n",
        "    \n",
        "    # Combine the features: You can either keep TF-IDF and features separate or concatenate them as one feature matrix\n",
        "    combined_features = np.hstack([tfidf_sentence1_array, tfidf_sentence2_array, additional_features])\n",
        "    \n",
        "    # Return the processed DataFrame with the combined features\n",
        "    return combined_features, data, vectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Irz_4Wm6IyXb"
      },
      "source": [
        "# Initial models\n",
        "\n",
        "Each model should have the following:\n",
        "1. A train function that takes in the training data and gives back a model\n",
        "2. An evaluate function that takes the model and data, giving back predicted scores\n",
        "\n",
        "These predictions will be passed with true scores to the calculate metrics function which returns a set of evaluation metrics. They can be displayed with the display metrics function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_metrics(preds, scores):\n",
        "    pearson_corr, _ = pearsonr(scores, preds)\n",
        "    spearman_corr, _ = spearmanr(scores, preds)\n",
        "    _, _, r, _, _ = linregress(scores, preds)\n",
        "    r2 = r**2\n",
        "    mse = ((scores - preds)**2).mean()\n",
        "    return (pearson_corr, spearman_corr, r2, mse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def display_metrics(metrics, title=\"Metrics:\"):\n",
        "    print(title)\n",
        "    print(\"Pearson Corr:\", metrics[0])\n",
        "    print(\"Spearman Corr:\", metrics[1])\n",
        "    print(\"R^2:\", metrics[2])\n",
        "    print(\"MSE:\", metrics[3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Jtr56u-BIyXc"
      },
      "outputs": [],
      "source": [
        "def train_lr(train_features, train_labels):\n",
        "    model = LinearRegression()\n",
        "    model.fit(train_features, train_labels)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_lr(model, features):\n",
        "    return model.predict(features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PairID</th>\n",
              "      <th>Text</th>\n",
              "      <th>Score</th>\n",
              "      <th>Split_Text</th>\n",
              "      <th>Pred_Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ENG-dev-0000</td>\n",
              "      <td>The story is gripping and interesting.\\nIt's a...</td>\n",
              "      <td>0.64</td>\n",
              "      <td>[The story is gripping and interesting., It's ...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ENG-dev-0001</td>\n",
              "      <td>The majority of Southeast Alaska 's area is pa...</td>\n",
              "      <td>0.61</td>\n",
              "      <td>[The majority of Southeast Alaska 's area is p...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ENG-dev-0002</td>\n",
              "      <td>and from your post i think you are to young to...</td>\n",
              "      <td>0.31</td>\n",
              "      <td>[and from your post i think you are to young t...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ENG-dev-0003</td>\n",
              "      <td>The film 's success also made Dreamworks Anima...</td>\n",
              "      <td>0.59</td>\n",
              "      <td>[The film 's success also made Dreamworks Anim...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ENG-dev-0004</td>\n",
              "      <td>I am still confused about how I feel about thi...</td>\n",
              "      <td>0.50</td>\n",
              "      <td>[I am still confused about how I feel about th...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         PairID                                               Text  Score  \\\n",
              "0  ENG-dev-0000  The story is gripping and interesting.\\nIt's a...   0.64   \n",
              "1  ENG-dev-0001  The majority of Southeast Alaska 's area is pa...   0.61   \n",
              "2  ENG-dev-0002  and from your post i think you are to young to...   0.31   \n",
              "3  ENG-dev-0003  The film 's success also made Dreamworks Anima...   0.59   \n",
              "4  ENG-dev-0004  I am still confused about how I feel about thi...   0.50   \n",
              "\n",
              "                                          Split_Text  Pred_Score  \n",
              "0  [The story is gripping and interesting., It's ...         0.0  \n",
              "1  [The majority of Southeast Alaska 's area is p...         0.0  \n",
              "2  [and from your post i think you are to young t...         0.0  \n",
              "3  [The film 's success also made Dreamworks Anim...         0.0  \n",
              "4  [I am still confused about how I feel about th...         0.0  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data = load_data(\"./Semantic_Relatedness_SemEval2024/Track A/eng/eng_dev_with_labels.csv\")\n",
        "train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PairID</th>\n",
              "      <th>Text</th>\n",
              "      <th>Score</th>\n",
              "      <th>Split_Text</th>\n",
              "      <th>Pred_Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ENG-test-0000</td>\n",
              "      <td>Egypt's Brotherhood stands ground after killin...</td>\n",
              "      <td>0.70</td>\n",
              "      <td>[Egypt's Brotherhood stands ground after killi...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ENG-test-0001</td>\n",
              "      <td>install it for fre and get to know what all u ...</td>\n",
              "      <td>0.71</td>\n",
              "      <td>[install it for fre and get to know what all u...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ENG-test-0002</td>\n",
              "      <td>Also, it was one of the debut novels that I wa...</td>\n",
              "      <td>0.49</td>\n",
              "      <td>[Also, it was one of the debut novels that I w...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ENG-test-0003</td>\n",
              "      <td>Therefore, you can use the code BRAIL, BASIL, ...</td>\n",
              "      <td>0.27</td>\n",
              "      <td>[Therefore, you can use the code BRAIL, BASIL,...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ENG-test-0004</td>\n",
              "      <td>Solid YA novel with a funky take on zombies an...</td>\n",
              "      <td>0.32</td>\n",
              "      <td>[Solid YA novel with a funky take on zombies a...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          PairID                                               Text  Score  \\\n",
              "0  ENG-test-0000  Egypt's Brotherhood stands ground after killin...   0.70   \n",
              "1  ENG-test-0001  install it for fre and get to know what all u ...   0.71   \n",
              "2  ENG-test-0002  Also, it was one of the debut novels that I wa...   0.49   \n",
              "3  ENG-test-0003  Therefore, you can use the code BRAIL, BASIL, ...   0.27   \n",
              "4  ENG-test-0004  Solid YA novel with a funky take on zombies an...   0.32   \n",
              "\n",
              "                                          Split_Text  Pred_Score  \n",
              "0  [Egypt's Brotherhood stands ground after killi...         0.0  \n",
              "1  [install it for fre and get to know what all u...         0.0  \n",
              "2  [Also, it was one of the debut novels that I w...         0.0  \n",
              "3  [Therefore, you can use the code BRAIL, BASIL,...         0.0  \n",
              "4  [Solid YA novel with a funky take on zombies a...         0.0  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data = load_data(\"./Semantic_Relatedness_SemEval2024/Track A/eng/eng_test_with_labels.csv\")\n",
        "test_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(250, 14)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PairID</th>\n",
              "      <th>Text</th>\n",
              "      <th>Score</th>\n",
              "      <th>Split_Text</th>\n",
              "      <th>Pred_Score</th>\n",
              "      <th>Sentence1</th>\n",
              "      <th>Sentence2</th>\n",
              "      <th>Tokens_Sentence1</th>\n",
              "      <th>Tokens_Sentence2</th>\n",
              "      <th>Cosine_Similarity</th>\n",
              "      <th>Jaccard_Similarity</th>\n",
              "      <th>Levenshtein_Distance</th>\n",
              "      <th>Length_Diff</th>\n",
              "      <th>Word_Overlap</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ENG-dev-0000</td>\n",
              "      <td>The story is gripping and interesting.\\nIt's a...</td>\n",
              "      <td>0.64</td>\n",
              "      <td>[The story is gripping and interesting., It's ...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>the story is gripping and interesting</td>\n",
              "      <td>its a brilliant compelling and heartfelt story</td>\n",
              "      <td>[the, story, is, gripping, and, interesting]</td>\n",
              "      <td>[its, a, brilliant, compelling, and, heartfelt...</td>\n",
              "      <td>0.356736</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>29</td>\n",
              "      <td>9</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ENG-dev-0001</td>\n",
              "      <td>The majority of Southeast Alaska 's area is pa...</td>\n",
              "      <td>0.61</td>\n",
              "      <td>[The majority of Southeast Alaska 's area is p...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>the majority of southeast alaska s area is par...</td>\n",
              "      <td>a lot of of the panhandle is part of the tonga...</td>\n",
              "      <td>[the, majority, of, southeast, alaska, s, area...</td>\n",
              "      <td>[a, lot, of, of, the, panhandle, is, part, of,...</td>\n",
              "      <td>0.790995</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>62</td>\n",
              "      <td>1</td>\n",
              "      <td>0.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ENG-dev-0002</td>\n",
              "      <td>and from your post i think you are to young to...</td>\n",
              "      <td>0.31</td>\n",
              "      <td>[and from your post i think you are to young t...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>and from your post i think you are to young to...</td>\n",
              "      <td>i think it will be very bad if he acquires her...</td>\n",
              "      <td>[and, from, your, post, i, think, you, are, to...</td>\n",
              "      <td>[i, think, it, will, be, very, bad, if, he, ac...</td>\n",
              "      <td>0.157548</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>53</td>\n",
              "      <td>15</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ENG-dev-0003</td>\n",
              "      <td>The film 's success also made Dreamworks Anima...</td>\n",
              "      <td>0.59</td>\n",
              "      <td>[The film 's success also made Dreamworks Anim...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>the film s success also made dreamworks animat...</td>\n",
              "      <td>there have also been two sequels lrb followups...</td>\n",
              "      <td>[the, film, s, success, also, made, dreamworks...</td>\n",
              "      <td>[there, have, also, been, two, sequels, lrb, f...</td>\n",
              "      <td>0.680547</td>\n",
              "      <td>0.269231</td>\n",
              "      <td>79</td>\n",
              "      <td>26</td>\n",
              "      <td>0.411765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ENG-dev-0004</td>\n",
              "      <td>I am still confused about how I feel about thi...</td>\n",
              "      <td>0.50</td>\n",
              "      <td>[I am still confused about how I feel about th...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>i am still confused about how i feel about thi...</td>\n",
              "      <td>in this particular book blue and gansey are st...</td>\n",
              "      <td>[i, am, still, confused, about, how, i, feel, ...</td>\n",
              "      <td>[in, this, particular, book, blue, and, gansey...</td>\n",
              "      <td>0.231539</td>\n",
              "      <td>0.120000</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         PairID                                               Text  Score  \\\n",
              "0  ENG-dev-0000  The story is gripping and interesting.\\nIt's a...   0.64   \n",
              "1  ENG-dev-0001  The majority of Southeast Alaska 's area is pa...   0.61   \n",
              "2  ENG-dev-0002  and from your post i think you are to young to...   0.31   \n",
              "3  ENG-dev-0003  The film 's success also made Dreamworks Anima...   0.59   \n",
              "4  ENG-dev-0004  I am still confused about how I feel about thi...   0.50   \n",
              "\n",
              "                                          Split_Text  Pred_Score  \\\n",
              "0  [The story is gripping and interesting., It's ...         0.0   \n",
              "1  [The majority of Southeast Alaska 's area is p...         0.0   \n",
              "2  [and from your post i think you are to young t...         0.0   \n",
              "3  [The film 's success also made Dreamworks Anim...         0.0   \n",
              "4  [I am still confused about how I feel about th...         0.0   \n",
              "\n",
              "                                           Sentence1  \\\n",
              "0              the story is gripping and interesting   \n",
              "1  the majority of southeast alaska s area is par...   \n",
              "2  and from your post i think you are to young to...   \n",
              "3  the film s success also made dreamworks animat...   \n",
              "4  i am still confused about how i feel about thi...   \n",
              "\n",
              "                                           Sentence2  \\\n",
              "0     its a brilliant compelling and heartfelt story   \n",
              "1  a lot of of the panhandle is part of the tonga...   \n",
              "2  i think it will be very bad if he acquires her...   \n",
              "3  there have also been two sequels lrb followups...   \n",
              "4  in this particular book blue and gansey are st...   \n",
              "\n",
              "                                    Tokens_Sentence1  \\\n",
              "0       [the, story, is, gripping, and, interesting]   \n",
              "1  [the, majority, of, southeast, alaska, s, area...   \n",
              "2  [and, from, your, post, i, think, you, are, to...   \n",
              "3  [the, film, s, success, also, made, dreamworks...   \n",
              "4  [i, am, still, confused, about, how, i, feel, ...   \n",
              "\n",
              "                                    Tokens_Sentence2  Cosine_Similarity  \\\n",
              "0  [its, a, brilliant, compelling, and, heartfelt...           0.356736   \n",
              "1  [a, lot, of, of, the, panhandle, is, part, of,...           0.790995   \n",
              "2  [i, think, it, will, be, very, bad, if, he, ac...           0.157548   \n",
              "3  [there, have, also, been, two, sequels, lrb, f...           0.680547   \n",
              "4  [in, this, particular, book, blue, and, gansey...           0.231539   \n",
              "\n",
              "   Jaccard_Similarity  Levenshtein_Distance  Length_Diff  Word_Overlap  \n",
              "0            0.181818                    29            9      0.333333  \n",
              "1            0.428571                    62            1      0.600000  \n",
              "2            0.125000                    53           15      0.200000  \n",
              "3            0.269231                    79           26      0.411765  \n",
              "4            0.120000                    89           66      0.333333  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_features, train_data, vectorizer = preprocess_data(train_data)\n",
        "print(train_data.shape)\n",
        "train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(250, 2453)\n",
            "[[ 0.          0.          0.         ... 29.          9.\n",
            "   0.33333333]\n",
            " [ 0.          0.          0.         ... 62.          1.\n",
            "   0.6       ]\n",
            " [ 0.          0.          0.         ... 53.         15.\n",
            "   0.2       ]\n",
            " ...\n",
            " [ 0.          0.          0.         ... 86.         15.\n",
            "   0.42105263]\n",
            " [ 0.          0.          0.         ... 31.         25.\n",
            "   0.41666667]\n",
            " [ 0.          0.          0.         ... 28.         28.\n",
            "   1.        ]]\n"
          ]
        }
      ],
      "source": [
        "print(train_features.shape)\n",
        "print(train_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(250,)\n",
            "[0.64 0.61 0.31 0.59 0.5  0.42 0.7  0.7  0.59 0.63 0.73 0.63 0.56 0.35\n",
            " 0.32 0.64 0.44 0.64 0.7  0.48 0.42 0.32 0.25 0.22 0.41 0.88 0.5  0.45\n",
            " 0.42 0.42 0.36 0.3  0.68 0.73 0.77 0.35 0.39 0.41 0.33 0.87 0.53 0.71\n",
            " 0.5  0.76 0.77 0.3  0.59 0.57 0.73 0.4  0.33 0.41 0.61 0.48 0.61 0.59\n",
            " 0.45 0.56 0.65 0.3  0.37 0.62 0.36 0.58 0.54 0.39 0.57 0.52 0.48 0.43\n",
            " 0.52 0.63 0.36 0.5  0.73 0.39 0.44 0.56 0.58 0.59 0.39 0.68 0.41 0.37\n",
            " 0.35 0.41 0.59 0.31 0.47 0.67 0.7  0.52 0.65 0.44 0.73 0.42 0.19 0.32\n",
            " 0.82 0.61 0.54 0.68 0.42 0.73 0.46 0.21 0.77 0.55 0.57 0.29 0.55 0.66\n",
            " 0.28 0.72 0.31 0.47 0.56 0.45 0.21 0.7  0.58 0.66 0.69 0.42 0.6  0.45\n",
            " 0.43 0.45 0.26 0.34 0.59 0.74 0.54 0.41 0.64 0.31 0.3  0.24 0.39 0.63\n",
            " 0.62 0.62 0.55 0.45 0.52 0.39 0.52 0.68 0.65 0.62 0.58 0.39 0.44 0.4\n",
            " 0.38 0.46 0.27 0.39 0.53 0.6  0.68 0.63 0.48 0.49 0.36 0.64 0.63 0.52\n",
            " 0.5  0.43 0.48 0.48 0.33 0.5  0.35 0.35 0.37 0.4  0.72 0.8  0.65 0.24\n",
            " 0.45 0.39 0.46 0.3  0.65 0.31 0.56 0.4  0.38 0.67 0.35 0.52 0.66 0.53\n",
            " 0.47 0.55 0.67 0.37 0.4  0.45 0.3  0.83 0.52 0.73 0.36 0.85 0.41 0.8\n",
            " 0.34 0.5  0.5  0.45 0.4  0.3  0.5  0.44 0.54 0.36 0.48 0.48 0.72 0.59\n",
            " 0.73 0.32 0.53 0.69 0.31 0.27 0.37 0.45 0.36 0.28 0.5  0.71 0.26 0.72\n",
            " 0.52 0.46 0.35 0.89 0.61 0.4  0.68 0.5  0.48 0.58 0.4  0.91]\n"
          ]
        }
      ],
      "source": [
        "train_labels = train_data['Score'].to_numpy()\n",
        "print(train_labels.shape)\n",
        "print(train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2600, 14)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PairID</th>\n",
              "      <th>Text</th>\n",
              "      <th>Score</th>\n",
              "      <th>Split_Text</th>\n",
              "      <th>Pred_Score</th>\n",
              "      <th>Sentence1</th>\n",
              "      <th>Sentence2</th>\n",
              "      <th>Tokens_Sentence1</th>\n",
              "      <th>Tokens_Sentence2</th>\n",
              "      <th>Cosine_Similarity</th>\n",
              "      <th>Jaccard_Similarity</th>\n",
              "      <th>Levenshtein_Distance</th>\n",
              "      <th>Length_Diff</th>\n",
              "      <th>Word_Overlap</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ENG-test-0000</td>\n",
              "      <td>Egypt's Brotherhood stands ground after killin...</td>\n",
              "      <td>0.70</td>\n",
              "      <td>[Egypt's Brotherhood stands ground after killi...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>egypts brotherhood stands ground after killings</td>\n",
              "      <td>egypt muslim brotherhood stands behind morsi</td>\n",
              "      <td>[egypts, brotherhood, stands, ground, after, k...</td>\n",
              "      <td>[egypt, muslim, brotherhood, stands, behind, m...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>22</td>\n",
              "      <td>3</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ENG-test-0001</td>\n",
              "      <td>install it for fre and get to know what all u ...</td>\n",
              "      <td>0.71</td>\n",
              "      <td>[install it for fre and get to know what all u...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>install it for fre and get to know what all u ...</td>\n",
              "      <td>install the program which is free to download ...</td>\n",
              "      <td>[install, it, for, fre, and, get, to, know, wh...</td>\n",
              "      <td>[install, the, program, which, is, free, to, d...</td>\n",
              "      <td>0.534905</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>53</td>\n",
              "      <td>28</td>\n",
              "      <td>0.461538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ENG-test-0002</td>\n",
              "      <td>Also, it was one of the debut novels that I wa...</td>\n",
              "      <td>0.49</td>\n",
              "      <td>[Also, it was one of the debut novels that I w...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>also it was one of the debut novels that i was...</td>\n",
              "      <td>pretty much the first thing people mentioned w...</td>\n",
              "      <td>[also, it, was, one, of, the, debut, novels, t...</td>\n",
              "      <td>[pretty, much, the, first, thing, people, ment...</td>\n",
              "      <td>0.025541</td>\n",
              "      <td>0.120000</td>\n",
              "      <td>61</td>\n",
              "      <td>20</td>\n",
              "      <td>0.214286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ENG-test-0003</td>\n",
              "      <td>Therefore, you can use the code BRAIL, BASIL, ...</td>\n",
              "      <td>0.27</td>\n",
              "      <td>[Therefore, you can use the code BRAIL, BASIL,...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>therefore you can use the code brail basil etc</td>\n",
              "      <td>you can watch the wiggles every day on nick jr</td>\n",
              "      <td>[therefore, you, can, use, the, code, brail, b...</td>\n",
              "      <td>[you, can, watch, the, wiggles, every, day, on...</td>\n",
              "      <td>0.672660</td>\n",
              "      <td>0.187500</td>\n",
              "      <td>37</td>\n",
              "      <td>0</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ENG-test-0004</td>\n",
              "      <td>Solid YA novel with a funky take on zombies an...</td>\n",
              "      <td>0.32</td>\n",
              "      <td>[Solid YA novel with a funky take on zombies a...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>solid ya novel with a funky take on zombies an...</td>\n",
              "      <td>my 13yearold son recommended this book to me a...</td>\n",
              "      <td>[solid, ya, novel, with, a, funky, take, on, z...</td>\n",
              "      <td>[my, 13yearold, son, recommended, this, book, ...</td>\n",
              "      <td>0.045587</td>\n",
              "      <td>0.035714</td>\n",
              "      <td>59</td>\n",
              "      <td>25</td>\n",
              "      <td>0.083333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          PairID                                               Text  Score  \\\n",
              "0  ENG-test-0000  Egypt's Brotherhood stands ground after killin...   0.70   \n",
              "1  ENG-test-0001  install it for fre and get to know what all u ...   0.71   \n",
              "2  ENG-test-0002  Also, it was one of the debut novels that I wa...   0.49   \n",
              "3  ENG-test-0003  Therefore, you can use the code BRAIL, BASIL, ...   0.27   \n",
              "4  ENG-test-0004  Solid YA novel with a funky take on zombies an...   0.32   \n",
              "\n",
              "                                          Split_Text  Pred_Score  \\\n",
              "0  [Egypt's Brotherhood stands ground after killi...         0.0   \n",
              "1  [install it for fre and get to know what all u...         0.0   \n",
              "2  [Also, it was one of the debut novels that I w...         0.0   \n",
              "3  [Therefore, you can use the code BRAIL, BASIL,...         0.0   \n",
              "4  [Solid YA novel with a funky take on zombies a...         0.0   \n",
              "\n",
              "                                           Sentence1  \\\n",
              "0    egypts brotherhood stands ground after killings   \n",
              "1  install it for fre and get to know what all u ...   \n",
              "2  also it was one of the debut novels that i was...   \n",
              "3     therefore you can use the code brail basil etc   \n",
              "4  solid ya novel with a funky take on zombies an...   \n",
              "\n",
              "                                           Sentence2  \\\n",
              "0       egypt muslim brotherhood stands behind morsi   \n",
              "1  install the program which is free to download ...   \n",
              "2  pretty much the first thing people mentioned w...   \n",
              "3     you can watch the wiggles every day on nick jr   \n",
              "4  my 13yearold son recommended this book to me a...   \n",
              "\n",
              "                                    Tokens_Sentence1  \\\n",
              "0  [egypts, brotherhood, stands, ground, after, k...   \n",
              "1  [install, it, for, fre, and, get, to, know, wh...   \n",
              "2  [also, it, was, one, of, the, debut, novels, t...   \n",
              "3  [therefore, you, can, use, the, code, brail, b...   \n",
              "4  [solid, ya, novel, with, a, funky, take, on, z...   \n",
              "\n",
              "                                    Tokens_Sentence2  Cosine_Similarity  \\\n",
              "0  [egypt, muslim, brotherhood, stands, behind, m...           0.000000   \n",
              "1  [install, the, program, which, is, free, to, d...           0.534905   \n",
              "2  [pretty, much, the, first, thing, people, ment...           0.025541   \n",
              "3  [you, can, watch, the, wiggles, every, day, on...           0.672660   \n",
              "4  [my, 13yearold, son, recommended, this, book, ...           0.045587   \n",
              "\n",
              "   Jaccard_Similarity  Levenshtein_Distance  Length_Diff  Word_Overlap  \n",
              "0            0.200000                    22            3      0.333333  \n",
              "1            0.285714                    53           28      0.461538  \n",
              "2            0.120000                    61           20      0.214286  \n",
              "3            0.187500                    37            0      0.333333  \n",
              "4            0.035714                    59           25      0.083333  "
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_features, test_data, _ = preprocess_data(test_data, vectorizer, False)\n",
        "print(test_data.shape)\n",
        "test_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2600, 2453)\n",
            "[[ 0.          0.          0.         ... 22.          3.\n",
            "   0.33333333]\n",
            " [ 0.          0.          0.         ... 53.         28.\n",
            "   0.46153846]\n",
            " [ 0.          0.          0.         ... 61.         20.\n",
            "   0.21428571]\n",
            " ...\n",
            " [ 0.          0.          0.         ... 29.         16.\n",
            "   0.2       ]\n",
            " [ 0.          0.          0.         ... 41.         16.\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ... 65.         40.\n",
            "   0.1875    ]]\n"
          ]
        }
      ],
      "source": [
        "print(test_features.shape)\n",
        "print(test_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2600,)\n",
            "[0.7  0.71 0.49 ... 0.45 0.45 0.22]\n"
          ]
        }
      ],
      "source": [
        "test_labels = test_data['Score'].to_numpy()\n",
        "print(test_labels.shape)\n",
        "print(test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evaluate Initial Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Metrics:\n",
            "Pearson Corr: 1.0\n",
            "Spearman Corr: 0.9996848720960497\n",
            "R^2: 1.0\n",
            "MSE: 1.4407530624339056e-29\n",
            "\n",
            "Testing Metrics:\n",
            "Pearson Corr: 0.6440257081976024\n",
            "Spearman Corr: 0.6446774366625729\n",
            "R^2: 0.41476911281942375\n",
            "MSE: 0.017092369388471442\n"
          ]
        }
      ],
      "source": [
        "model_lr = train_lr(train_features, train_labels)\n",
        "train_preds_lr = evaluate_lr(model_lr, train_features)\n",
        "test_preds_lr = evaluate_lr(model_lr, test_features)\n",
        "train_metrics_lr = calculate_metrics(train_preds_lr, train_labels)\n",
        "test_metrics_lr = calculate_metrics(test_preds_lr, test_labels)\n",
        "display_metrics(train_metrics_lr, \"Training Metrics:\")\n",
        "print()\n",
        "display_metrics(test_metrics_lr, \"Testing Metrics:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pred vs True for training data\n",
            "0.6400, 0.6400\n",
            "0.6100, 0.6100\n",
            "0.3100, 0.3100\n",
            "0.5900, 0.5900\n",
            "0.5000, 0.5000\n",
            "0.4200, 0.4200\n",
            "0.7000, 0.7000\n",
            "0.7000, 0.7000\n",
            "0.5900, 0.5900\n",
            "0.6300, 0.6300\n",
            "\n",
            "Pred vs True for testing data\n",
            "0.4637, 0.7000\n",
            "0.4821, 0.7100\n",
            "0.5607, 0.4900\n",
            "0.5193, 0.2700\n",
            "0.3441, 0.3200\n",
            "0.3618, 0.4300\n",
            "0.4547, 0.3100\n",
            "0.3502, 0.3200\n",
            "0.5306, 0.7700\n",
            "0.5330, 0.3400\n"
          ]
        }
      ],
      "source": [
        "print(\"Pred vs True for training data\")\n",
        "for i in range(10):\n",
        "    print(f\"{train_preds_lr[i]:.4f}, {train_labels[i]:.4f}\")\n",
        "print()\n",
        "print(\"Pred vs True for testing data\")\n",
        "for i in range(10):\n",
        "    print(f\"{test_preds_lr[i]:.4f}, {test_labels[i]:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
